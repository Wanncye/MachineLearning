# README
>我发现只看机器学习原理，存在两个问题：
* 1.有些算法的原理难以理解
* 2.就算理解了，也不知道实现思路，只能当个调包侠  
>因此，决定借鉴一下别人实现的代码，看看具体的实现思想，也方便更加深入的理解这些机器学习算法。
其中包括：
* 1.GBDT算法:[https://github.com/Freemanzxp/GBDT_Simple_Tutorial](https://github.com/Freemanzxp/GBDT_Simple_Tutorial)
>如何做特征选择？如何做分类？
* 2.DecisionTree:[https://github.com/lucksd356/DecisionTrees](https://github.com/lucksd356/DecisionTrees)
>只实现了ID3算法，其他两种C4.5，CART在计算增益这一块用的是不同的指标。
这里列出三种决策树的[区别](https://blog.csdn.net/qq_27717921/article/details/74784400)
* 3.XgBoost:[https://blog.csdn.net/slx_share/article/details/82389343](代码来自这个博客)，公式推导我觉得讲的最详细的是[这篇文章](https://zhuanlan.zhihu.com/p/92837676)。
>Xgboost的目标函数、公式推导、GBDT与Xgboost的区别、Xgboost的正则化原理，这些都是需要掌握的问题。
* 4.RandomForest:[https://github.com/zhaoxingfeng/RandomForest](https://github.com/zhaoxingfeng/RandomForest)
>RF为什么要随机抽样？又为什么做有放回的采样？
* 5.AdaBoost:[https://github.com/jaimeps/adaboost-implementation/tree/master](https://github.com/jaimeps/adaboost-implementation/tree/master)
>权值更新的方法、为什么能快速收敛、优缺点
* 6.SVM:[https://vimsky.com/article/222.html](https://vimsky.com/article/222.html),实现的是HingeLoss版本的SVM
>什么叫硬间隔？什么叫软间隔？SVM为什么采用间隔最大化？为什么使用核函数？
* 7.MLE:[https://blog.csdn.net/pengjian444/article/details/71215965](https://blog.csdn.net/pengjian444/article/details/71215965)
* TODO
* 8.MAP、贝叶斯估计、EM
* 8.PCA
* 9.LDA
* 10.KNN

